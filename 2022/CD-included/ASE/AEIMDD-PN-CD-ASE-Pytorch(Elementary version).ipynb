{"cells":[{"cell_type":"markdown","metadata":{"id":"Z6cOYGiq_Dsv"},"source":["# Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tPswMr4WASlo"},"outputs":[],"source":["from weakref import ref\n","import numpy as np\n","import torch\n","\n","from torch.autograd import Variable\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.distributions.normal import Normal\n","from torchvision import transforms\n","from torch.nn.modules.distance import PairwiseDistance\n","from copy import copy\n","import matplotlib.pyplot as plt\n","\n","from datetime import time, date, datetime\n","import time\n","import pickle\n","import random\n","import sys\n","import itertools\n","\n","import math\n","import matplotlib\n","from matplotlib.colors import ListedColormap\n","\n","from mpl_toolkits.axisartist.axislines import SubplotZero\n","import warnings\n","from matplotlib.axes._axes import _log as matplotlib_axes_logger\n","matplotlib_axes_logger.setLevel('ERROR')\n","\n","import scipy\n","import scipy.io as io \n","import copy\n","\n","from mpl_toolkits.axisartist.axislines import SubplotZero\n","from scipy.integrate import quad\n","from scipy.stats import norm\n","from scipy.interpolate import interp1d\n","from sympy.combinatorics.graycode import GrayCode\n","import pickle as pkl\n","import os\n","\n","from IPython import display\n","from pathlib import Path\n","from IPython.core.pylabtools import figsize\n","from numpy.core.fromnumeric import size\n","\n","\n","\n","class AttrDict(dict):\n","    def __init__(self, *args, **kwargs):\n","        super(AttrDict, self).__init__(*args, **kwargs)\n","        self.__dict__ = self\n","\n","def binary_batch_to_decimal(Targets):\n","    \"\"\"\n","    This Function Takes a Matrix of the size N * S\n","    - N number of symbols\n","    - S Symbol size (#Bits of each symbol )\n","    and returns a tensor of integers \n","    Example: \n","    Targets: [[0, 1, 1, 0, 0, 1],\n","              [1, 0, 1, 1, 0, 1],\n","              [1, 1, 1, 0, 1, 1]]\n","    int_Targets: [3, 5, 2, 1, 7]\n","    \"\"\"\n","    int_Targets = np.zeros([len(Targets[:,0])])    \n","    for j in range(len(Targets[:,0])):\n","        x=0\n","        l=len(Targets[0,:])\n","        for i in range(l):\n","                x+=Targets[j,i]*2**(l-1-i) \n","        int_Targets[j]=x\n","    return int_Targets.reshape(-1,1)\n","\n","def tx_PAM_Gen(ModuFormat, b_size): \n","  '''\n","  This fuction generates PAM symbols \n","  input: \n","    sys: attribute dictionary of system parameters \n","  output:\n","    ref_Bit: the random bits generated\n","    ref_PAM: the PAM optical coordiantes (any of [0,1,2,3])\n","  '''\n","  \n","  # ModuFormat = syst.PMA_order\n","\n","  ## bit generation\n","\n","  rbs = np.random.randint(0,2,(b_size,1))\n","\n","  k_bits = np.log2(ModuFormat)\n","  Nsymbs = np.floor(np.max(np.size((rbs)))/k_bits)\n","\n","  ref_BIT = rbs[0:int(Nsymbs*k_bits)]\n","  \n","  ## PAM level generation\n","  bit_matrix = ref_BIT.reshape(int(Nsymbs),int(k_bits))\n","  tx_vec = binary_batch_to_decimal(bit_matrix)\n","  \n","\n","  ref_PAM = tx_vec # pammod(tx_vec,ModuFormat);\n","\n","  return ref_BIT,ref_PAM\n","\n","def rectpulse(ref_PAM, syst):\n","\t\"\"\"\n","\t\tParameters\n","\t\t------------\n","\t\tref_PAM: a sequence of PAM symbols for examplpe for PAM 4 [0,1,2,3] \n","    syst: atribute dictionary of the system \n","      syst.puls_sps is used here which determines the sample per symbol ratio\n","\t\tsamplesPerSymbol\n","\n","\t\tReturns\n","\t\t------------\n","\t\toutNRZ: NRZ train pulses. \n","\t\"\"\"\n","\toutNRZ = [ref_PAM[i] for i in range(0,len(ref_PAM)) for j in range(0,syst.puls_sps)]\n","\toutNRZ = np.array(outNRZ) \t\n","\treturn outNRZ\n","\n","def add_laser_PN(Data_in_Func, laser): \n","  NoiseSamp = np.random.randn(np.max(np.size(Data_in_Func)), 2)\n","  PNt = (2*np.pi*laser.tx_linewidth*laser.d_t)*np.cumsum(NoiseSamp[:,0]).reshape(-1,1) # considers only firtst dimention of the NoiseSamp\n","  Data_out_Laser = np.sqrt(laser.power)*Data_in_Func*np.exp(1j*PNt) # transmitter phase noise\n","\n","  pow_total = np.mean(np.abs(Data_out_Laser)**2);\n","  # print('******Laser*********');  \n","  # print('Laser Linewidth = ',(laser.tx_linewidth/1e6),' MHz\\n')  \n","  \n","  return Data_out_Laser\n","\n","def add_fiber_CD(Data_in_Func, fiber): \n","  w_T = 2*np.pi*np.array(list(np.arange(0,np.max(np.size(Data_in_Func)/2)))+list(np.arange(-np.max(np.size(Data_in_Func))//2,0))).reshape(-1,1)/(np.max(np.size(Data_in_Func))/fiber.BW)\n","  w = w_T # +min(w_T);  \n","  HDispersion=np.exp(1j*(fiber.beta2*w**2*fiber.Length)/2+1j*(fiber.beta3*w**3*fiber.Length)/6)  \n","  # HDispersion=exp(1i*(fiber.beta2*w.^2*fiber.Length)/2);\n","  # HDispersion2=exp(-1i*(fiber.beta2*w.^2*fiber.Length)/2);\n","  # HDispersion=HDispersion1.*HDispersion2;\n","  f_fiber = np.fft.fftshift(w_T/(2e9*np.pi))\n","  # plt.plot(f_fiber, np.fft.fftshift((fiber.beta2*w**2*fiber.Length)/2+1j*(fier.beta3*w**3*fiber.Length)/6));\n","  \n","  # plt.xlabel('frequency (GHz)')\n","  # plt.ylabel('Fiber Phase Response (fiber.Dispersion caused)')\n","  # plt.title('Dispersion = {} ps/(nm*km)'.format(fiber.Dispersion))\n","  # plt.grid(True)\n","  # plt.show()\n","\n","  Data_out_Fiber = np.fft.ifft(np.fft.fft(Data_in_Func.reshape(1,-1))*HDispersion.reshape(1,-1))\n","  alpha=10**(0.05*fiber.Attenuation*fiber.Length);\n","  # %         Data_out_Fiber=Data_out_Fiber/sqrt(mean(abs(Data_out_Fiber.^2)));\n","  Data_out_Fiber=Data_out_Fiber.reshape(-1,1)/alpha;\n","\n","  # print('******Fiber*********');\n","  # print('Wavelength = {} nm'.format(fiber.lambdaa))\n","  # print('Fiber Length = {} Km'.format(fiber.Length))\n","  # print('Dispersion = {} ps/(nm*km)'.format(fiber.Dispersion))\n","  # print('Attenuation = {} dB/km'.format(fiber.Attenuation))\n","\n","  pow_total=np.mean(np.abs(Data_out_Fiber)**2);\n","  # print('***** Totoal Power Fiber Out *****\\n      ', pow_total,'\\n')\n","  return Data_out_Fiber\n","\n","def add_ASE(Data_out, syst):\n","  noise = ((1/np.sqrt(2)) * (np.random.randn(np.max(Data_out.shape)) + 1j * np.random.randn(np.max(Data_out.shape)))).reshape(-1,1)\n","  awgn = (np.sqrt(np.mean(np.abs(Data_out)**2)*(10**(-syst.ASE_SNR/10))) * noise)\n","  Data_out_ASE = Data_out + awgn\n","  return Data_out_ASE\n","\n","def PAM_resample_demodulate(Data_out, syst): \n","    \n","  # IMDD constellation generation for to be used for detection \n","  PAM_const = (np.sqrt(np.array([0,1,2,3]))).reshape(-1,1)\n","  PAM_const_norm = PAM_const\n","\n","  # resampling\n","  PAM_rx=Data_out[int(syst.puls_sps/2):-1:syst.puls_sps].reshape(1,-1)#sampling at half symbol duration\n","\n","  # demodulate\n","  RX = []\n","  for i in range(np.max(PAM_rx.shape)):\n","    idx = np.argmin(np.abs(PAM_rx[0,i]-PAM_const_norm**2))       \n","    RX.append(idx)  \n","  RX = np.array(RX).reshape(-1,1)\n","  return RX\n","\n","def messages_to_onehot(intMessages,M):\n","    \"\"\"\n","    Convert messages represented as indexes to one-hot encoding.\n","\n","    :param messages: List of messages to convert.\n","    :param order: Number of possible messages.\n","    :return: One-hot encoded messages.\n","\n","    Example: messages_to_onehot(torch.tensor([0, 2, 0, 3, 4])) =>>\n","    torch.tensor([\n","        [1., 0., 0., 0., 0.],\n","        [0., 0., 1., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 0., 0., 1., 0.],\n","\n","        [0., 0., 0., 0., 1.],\n","    ])\n","    \"\"\"\n","    return torch.nn.functional.one_hot(intMessages, num_classes=M).float()\n","\n","def get_sequential_data(x,seq_len, M):    \n","  \n","  win = []\n","  for i in range(torch.max(torch.tensor(x.shape))-seq_len+1):\n","    win.append(x[0,i:i+seq_len])\n","  win = torch.stack(win).reshape(1,-1)\n","  # print(win.shape)\n","  onehotTx = messages_to_onehot(win,M)\n","  win_onehotTx = onehotTx.reshape(-1,M*seq_len)\n","  return win_onehotTx\n","\n","def get_SER_BER_MC(model, trP):\n","    \"\"\"\n","    This function receives a constellation and a calculates\n","    Monte-Carlo BER \n","    \"\"\"\n","    \n","    \n","    ######################################################################\n","    # Initialization\n","    ######################################################################    \n","    bit_errors = 0\n","    bit_stream_size = 0\n","    N_symbols = 0\n","    sym_error_count = 0\n","    clip = torch.tensor((trP.seq_len-1)*2)\n","\n","    while sym_error_count < 100:\n","      ###      \n","      ######################################################################\n","      # Create Random data and convert it to one-hot\n","      ######################################################################\n","      ref_BIT,ref_PAM = tx_PAM_Gen(trP.M, trP.TSTbatchSize)  \n","      ref_PAM = torch.tensor(ref_PAM).reshape(1,-1).long().to(\"cuda\")            \n","      oneHot_seq = get_sequential_data(ref_PAM,trP.seq_len, trP.M).to(\"cuda\")    \n","\n","      # print('ref pam',ref_PAM.shape)\n","      # print('\\nTxone hot: ',oneHot_seq)\n","\n","      Tx = ref_PAM[0,:torch.max(torch.tensor(ref_PAM.shape))-clip]\n","      # print('\\ntx: ',Tx[:10])\n","      N_symbols += torch.max(torch.tensor(Tx.shape))\n","      # print('n s: ', N_symbols)\n","      ######################################################################\n","      # Apply random data to the model\n","      ######################################################################\n","      model.eval()\n","      with torch.no_grad():        \n","        scores, encOutNorm, channelOut  = model(oneHot_seq)\n","\n","        # print('\\nscores: ',scores.shape)\n","\n","        m = nn.Softmax(dim=1)\n","        probabilities = m(scores)\n","        # print('\\nprobabilities: ',probabilities.shape)\n","      \n","\n","        intRx = []\n","        # predictions = torch.zeros([len(probabilities), len(probabilities[0])], dtype=torch.float)       \n","        \n","        for i in range (len(probabilities)):  \n","          maximum_val, idx = torch.max(probabilities[i],dim=0)\n","          # predictions[i][idx]=1\n","          intRx.append(idx)\n","            \n","\n","  \n","        # intRx = torch.tensor([torch.where(r==1)[0][0] for r in predictions])\n","        \n","        intRx = torch.stack(intRx)        \n","        # print('\\nRX: ',intRx[:10])\n","        # for i in range(len(intRx)): \n","        #     if Tx[i] != intRx[i]:\n","        #         sym_error_count += 1\n","        # print(sym_error_count)\n","        # sys.exit()\n","        \n","        sym_error_count+=torch.sum(Tx != intRx)\n","        # print('EEERRROOOORSSSS: ',sym_error_count)\n","    SER = sym_error_count/N_symbols  \n","  \n","    return SER\n","\n","def set_attributes(): \n","  ##############################################################\n","  # System parameters\n","  syst = AttrDict()    \n","  syst.baud_rate  = 10e9\n","  syst.PMA_order  = 4\n","  syst.roll_off   = 1\n","  syst.puls_span  = 128\n","  syst.puls_sps   = 20\n","  syst.ASE_SNR    = 10\n","  ##############################################################\n","  # DAC parameters\n","  DAC = AttrDict()    # DAC parameters\n","  DAC.sampling_rate = syst.baud_rate*syst.puls_sps\n","  \n","  ##############################################################\n","  # fiber parameters\n","  fiber = AttrDict()   \n","  fiber.BW  = DAC.sampling_rate\n","  fiber.Length      = 3    # [KM]\n","  fiber.Dispersion  = 18   # [ps/(nm*km)]   (zero at 1310nm  and <=18 at 1550nm)\n","  fiber.S           = 0    # [ps/(nm^2.km)] Dispersion slope\n","  fiber.Attenuation = 0    # 0.2; % [dB/km]        (0.34 at 1310nm  and 0.2  at 1550nm)\n","  fiber.lambdaa     = 1550 # [nm] wavelength\n","  fiber.beta2       =-1*(fiber.Dispersion*1e-12*1e9*fiber.lambdaa**2*1e-18)/(2*np.pi*3e8)\n","  fiber.beta3       =-1*(fiber.S*1e-12*1e18*fiber.lambdaa**4*1e-36)/(2*np.pi*3e8)**2\n","\n","  ##############################################################\n","  # laser parameters\n","  laser = AttrDict()\n","  laser.power = torch.tensor(10**(0/10)) # 0 dBm\n","  laser.tx_linewidth = 1.6e8 #laser line width  \n","  laser.d_t = 1/(syst.baud_rate)\n","\n","  ##############################################################\n","  # training parameters\n","  trP = AttrDict()\n","  trP.M = syst.PMA_order\n","\n","  return syst, DAC, fiber, laser, trP\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"fazwS4Z0OfSn"},"source":["# Autoencoder model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E-GeuDd5OdUr"},"outputs":[],"source":["############################################################\n","## Class of Parameters\n","class ConstellationNet(nn.Module):\n","    \"\"\"\n","    This Class creates an Autoencoder srtucture which is used to \n","    train an End-to-End communication system.\n","    \"\"\"\n","    def __init__(self, syst=AttrDict(), DAC=AttrDict(), fiber=AttrDict(), laser=AttrDict(), trP=AttrDict()):\n","        \"\"\"\n","        Create an Autoencoder.\n","\n","        :param order: Order of the constellation, i.e. the number of \n","        messages that are to be transmitted, or equivalently the number\n","        of symbols whose placements in the constellation have to be \n","        learned.\n","\n","        :param encoder_layers: Shape of the encoder’s hidden layers. \n","        The size of this sequence is the number of hidden layers, with\n","        each element being a number which specifies the number of \n","        neurons in its channel.\n","\n","        :param decoder_layers: Shape of the decoder’s hidden layers. \n","        Uses the same convention as `encoder_layers_sizes` above.\n","        \"\"\"\n","        super(ConstellationNet, self).__init__()\n","        \n","        self.syst = syst\n","        self.DAC = DAC\n","        self.fiber = fiber\n","        self.laser = laser\n","        self.trP = trP\n","\n","\n","        self.encoder_layers = trP.layers\n","        self.decoder_layers = self.encoder_layers[::-1]\n","      \n","        self.prev_layer_size = self.trP.M*self.trP.seq_len\n","        self.encoder_layers_list = []\n","\n","        for self.layer_size in self.encoder_layers:\n","            self.encoder_layers_list.append(nn.Linear(self.prev_layer_size, self.layer_size,bias=True))            \n","            self.encoder_layers_list.append(nn.BatchNorm1d(self.layer_size))            \n","            self.encoder_layers_list.append(trP.activation)            \n","            \n","            self.prev_layer_size = self.layer_size\n","\n","        self.encoder_layers_list += [nn.Linear(self.prev_layer_size, 1), ]\n","\n","        self.encoder = nn.Sequential(*self.encoder_layers_list)\n","        #########################################################################\n","        # Build the decoder network taking the noisy I/Q vector received from\n","        # the channel as input and outputting a probability vector for each\n","        # original message. The network additionally uses hidden layers as\n","        # specified in `decoder_layers`\n","        #########################################################################\n","        self.prev_layer_size = 1*self.trP.seq_len\n","        self.decoder_layers_list = []\n","\n","        for self.layer_size in self.decoder_layers:\n","            self.decoder_layers_list.append(nn.Linear(self.prev_layer_size, self.layer_size,bias=True))\n","            self.decoder_layers_list.append(nn.BatchNorm1d(self.layer_size))\n","            self.decoder_layers_list.append(trP.activation)\n","                     \n","            self.prev_layer_size = self.layer_size\n","           \n","        self.decoder_layers_list.append(nn.Linear(self.prev_layer_size, self.trP.M))    \n","  \n","        self.decoder = nn.Sequential(*self.decoder_layers_list)\n","        \n","    def normalize_power_real(self, x):\n","        \"\"\"\n","        Normalization if constellation received in x is acomplished here.\n","        \"\"\" \n","        epsilon = 1e-12        \n","        average_power = (torch.sum(x**2))/(len(x))\n","        average_power = torch.max(torch.tensor([epsilon, average_power]))            \n","        normF = torch.rsqrt(average_power)\n","        x = x * normF       \n","        return  x\n","   \n","\n","    def get_decInp_win(self, x): \n","      a = x.reshape(-1)\n","      \n","      win=[]\n","      for i in range(0,((len(a)-self.trP.seq_len)+1),1):\n","        # print(i)\n","        win.append(a[i:i+self.trP.seq_len])\n","        \n","      # print(win)\n","      win = torch.stack(win)\n","      ww = win.reshape(-1,self.trP.seq_len)\n","      # print(ww)\n","      del win\n","      return ww\n","\n","    def rectpulse(self, x):\n","      \"\"\"\n","        Parameters\n","        ------------\n","        ref_PAM: a sequence of PAM symbols for examplpe for PAM 4 [0,1,2,3] \n","        syst: atribute dictionary of the system \n","          syst.puls_sps is used here which determines the sample per symbol ratio\n","        samplesPerSymbol\n","\n","        Returns\n","        ------------\n","        outNRZ: NRZ train pulses. \n","      \"\"\"\n","      outNRZ = [x[i] for i in range(0,len(x)) for j in range(0,syst.puls_sps)]\n","      outNRZ = torch.tensor(outNRZ) \t\n","      return outNRZ\n","        \n","    def add_laser_PN(self, Data_in_Func): \n","      Data_in_Func = Data_in_Func.reshape(-1,1)\n","      NoiseSamp = torch.randn(torch.max(torch.tensor(Data_in_Func.shape)), 2)\n","      \n","      PNt = (2*torch.pi*self.laser.tx_linewidth*self.laser.d_t)*torch.cumsum(NoiseSamp[:,0],dim=0).reshape(-1,1) # considers only firtst dimention of the NoiseSamp\n","\n","      Data_out_Laser = torch.sqrt(self.laser.power)*Data_in_Func*torch.exp(1j*PNt) # transmitter phase noise\n","      # pow_total = torch.mean(torch.abs(Data_out_Laser)**2);\n","      # # print('******Laser*********');  \n","      # # print('Laser Linewidth = ',(laser.tx_linewidth/1e6),' MHz\\n')  \n","      \n","      return Data_out_Laser\n","\n","    def add_fiber_CD(self, Data_in_Func): \n","      w_T = 2*torch.pi*torch.tensor(list(torch.arange(0,torch.max(torch.tensor(Data_in_Func.shape)/2)))+list(torch.arange(-torch.max(torch.tensor(Data_in_Func.shape))//2,0))).reshape(-1,1)/(torch.max(torch.tensor(Data_in_Func.shape))/self.fiber.BW)\n","      w = w_T # +min(w_T);  \n","      HDispersion=torch.exp(1j*(self.fiber.beta2*w**2*self.fiber.Length)/2+1j*(self.fiber.beta3*w**3*self.fiber.Length)/6)  \n","      # HDispersion=exp(1i*(fiber.beta2*w.^2*fiber.Length)/2);\n","      # HDispersion2=exp(-1i*(fiber.beta2*w.^2*fiber.Length)/2);\n","      # HDispersion=HDispersion1.*HDispersion2;\n","      f_fiber = torch.fft.fftshift(w_T/(2e9*torch.pi))\n","      # plt.plot(f_fiber, np.fft.fftshift((fiber.beta2*w**2*fiber.Length)/2+1j*(fier.beta3*w**3*fiber.Length)/6));\n","      \n","      # plt.xlabel('frequency (GHz)')\n","      # plt.ylabel('Fiber Phase Response (fiber.Dispersion caused)')\n","      # plt.title('Dispersion = {} ps/(nm*km)'.format(fiber.Dispersion))\n","      # plt.grid(True)\n","      # plt.show()\n","\n","      Data_out_Fiber = torch.fft.ifft(torch.fft.fft(Data_in_Func.reshape(1,-1))*HDispersion.reshape(1,-1))\n","      alpha=10**(0.05*self.fiber.Attenuation*self.fiber.Length);\n","      # %         Data_out_Fiber=Data_out_Fiber/sqrt(mean(abs(Data_out_Fiber.^2)));\n","      Data_out_Fiber=Data_out_Fiber.reshape(-1,1)/alpha;\n","\n","      # print('******Fiber*********');\n","      # print('Wavelength = {} nm'.format(fiber.lambdaa))\n","      # print('Fiber Length = {} Km'.format(fiber.Length))\n","      # print('Dispersion = {} ps/(nm*km)'.format(fiber.Dispersion))\n","      # print('Attenuation = {} dB/km'.format(fiber.Attenuation))\n","\n","      pow_total=torch.mean(torch.abs(Data_out_Fiber)**2);\n","      # print('***** Totoal Power Fiber Out *****\\n      ', pow_total,'\\n')\n","      return Data_out_Fiber\n","\n","    def add_ASE(self, Data_out):\n","      noise = ((1/torch.sqrt(torch.tensor(2))) * (torch.randn(torch.max(torch.tensor(Data_out.shape))) + 1j * torch.randn(torch.max(torch.tensor(Data_out.shape))))).reshape(-1,1)\n","      awgn = (torch.sqrt(torch.mean(torch.abs(Data_out)**2)*(10**(-self.syst.ASE_SNR/10))) * noise)\n","      Data_out_ASE = Data_out + awgn\n","      return Data_out_ASE\n","\n","    def PAM_resample(self, Data_out): \n","  \n","\n","      # resampling\n","      PAM_rx=Data_out[int(self.syst.puls_sps/2):-1:self.syst.puls_sps].reshape(1,-1)#sampling at half symbol duration\n","\n","  \n","      return PAM_rx\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Performs encoding and decoding of an input vector and compute its\n","        reconstructed vector.\n","\n","        :param x: Original one-hot encoded data.\n","        \n","        :return: Reconstructed vector. This Vector Containd Scores of be ing '1' or '0'\n","        \"\"\"        \n","        # print('x', x.shape)\n","        symbols = self.encoder(x) \n","        # print('symbols',symbols.shape)\n","        normalizedSymbols = self.normalize_power_real(symbols)\n","        # print('normalizedSymbols',normalizedSymbols.shape)\n","        # plt.plot(normalizedSymbols) \n","        PAM_shaped = self.rectpulse(normalizedSymbols)\n","        # print('PAM_shaped', PAM_shaped.shape)\n","        noisy_x = self.add_laser_PN(PAM_shaped)\n","        # print('noisy_x Laser', noisy_x.shape)\n","        noisy_x = self.add_fiber_CD(noisy_x)\n","        # print('noisy_x CD', noisy_x.shape)\n","        noisy_x = self.add_ASE(noisy_x)\n","        # print('noisy_x ASE', noisy_x.shape)\n","        noisy_x = torch.abs(noisy_x)**2\n","        # print('noisy_x FD', noisy_x.shape)\n","        noisy_x = self.PAM_resample(noisy_x).reshape(-1,1)\n","        # print('noisy_x RESAMP', noisy_x.shape)\n","        decInp = self.get_decInp_win(noisy_x).to(\"cuda\")\n","        # print('decInp', noisy_x.shape)\n","\n","        \n","        # sys.exit()\n","        \n","        dc = self.decoder(decInp)     \n","        return dc, normalizedSymbols, noisy_x \n"]},{"cell_type":"markdown","metadata":{"id":"_mALc1vZ-wcY"},"source":["#Train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":364},"id":"C5Q9DEpI-oYb","executionInfo":{"status":"error","timestamp":1677204727133,"user_tz":300,"elapsed":518,"user":{"displayName":"amir omidi","userId":"06486067205820177572"}},"outputId":"c2326626-5557-4c33-e65c-8de9b3dd7e21"},"outputs":[{"output_type":"stream","name":"stdout","text":["\t\t ---- Training Started!!! ----\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-84d5277f8185>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-34-84d5277f8185>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0msyst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mASE_SNR\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDAC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlaser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0mSERs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m   \u001b[0mSERs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSERs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-34-84d5277f8185>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(syst, DAC, fiber, laser, trP)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m## Get an instance of model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConstellationNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDAC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlaser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxavier_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'ConstellationNet' object is not iterable"]}],"source":["torch.set_printoptions(threshold=10_000)\n","np.random.seed(123)\n","# torch.random.manual_seed(123)\n","def train(syst, DAC, fiber, laser, trP):#, EncModel, DecModel):\n","   \n","  print('\\t\\t ---- Training Started!!! ----')\n","  \n","  ##############################################################\n","  ## Get an instance of model\n","  model = ConstellationNet(syst, DAC, fiber, laser, trP).to(\"cuda\")\n","  for layer in model:\n","    if isinstance(layer, nn.Linear):\n","        nn.init.xavier_uniform_(layer.weight)\n","\n","  criterion = torch.nn.CrossEntropyLoss()\n","  optimizer = torch.optim.RMSprop(model.parameters(), lr=trP.learningRate)\n","  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","      optimizer, \n","      verbose=True, #  If True, prints a message to stdout for each update. Default: False.\n","      factor=0.25, # Factor by which the learning rate will be reduced. new_lr = lr * factor. Default: 0.1.\n","      patience=100, # Number of epochs with no improvement after which learning rate will be reduced. \n","      cooldown=50, # Number of epochs to wait before resuming normal operation after lr has been reduced. Default: 0.\n","      threshold=1e-8 # Threshold for measuring the new optimum, to only focus on significant changes. Default: 1e-4.\n","  )\n","  ##############################################################\n","  clip = torch.tensor((trP.seq_len-1)*2)\n","\n","  \n","  i = 0\n","  losses = []\n","  best_ser = float('inf')\n","  while i <= trP.itrs:                \n","    ## PAM level generation (1-sps)\n","    ref_BIT,ref_PAM = tx_PAM_Gen(trP.M, trP.batchSize)  \n","    ref_PAM = torch.tensor(ref_PAM).reshape(1,-1).long().to(\"cuda\")\n","    oneHot_seq = get_sequential_data(ref_PAM,trP.seq_len, trP.M).to(\"cuda\")    \n","\n","    model.train()   \n","    model.eval()\n","    optimizer.zero_grad()    \n","    predictions, normalizedSymbols, noisy_x = model(oneHot_seq)   \n","       \n","    loss = criterion(predictions, ref_PAM[0,:torch.max(torch.tensor(ref_PAM.shape))-clip])  \n","    losses.append(loss.to(\"cpu\").detach().numpy())\n","\n","    loss.backward()        \n","    optimizer.step()\n","    scheduler.step(loss) ### Does the Update\n","    \n","    if i%(100)== 0:\n","      ser = get_SER_BER_MC(model, trP)     \n","      if ser < best_ser: \n","        best_ser = ser   \n","        plt.figure(figsize=(4,1),dpi=100)\n","      \n","      plt.scatter(noisy_x.detach().numpy(), np.zeros_like(noisy_x.detach().numpy()),s=20, alpha = .5, label='Received intensity');       \n","      plt.scatter(normalizedSymbols.to(\"cpu\").detach().numpy()**2,np.zeros_like(normalizedSymbols.to(\"cpu\").detach().numpy())**2,s=5, alpha = .5, label ='Transmitted intensity');       \n","     \n","       \n","      print('\\n\\t SNR: {}'.format(syst.ASE_SNR))  \n","      \n","      print('\\n\\t Itteration number: {}'.format(i))        \n","      print('\\t Current Loss is: {}'.format(loss))        \n","      # print('\\t Current movement is: {}'.format(total_change)) \n","      print('\\t Current SER is: {}'.format(ser)) \n","      print('\\t Best SER is: {}'.format(best_ser)) \n","      # print('\\n\\t current constellatiuon is: {}'.format(prev_constel))        \n","\n","      \n","      plt.show()\n","      plt.figure(figsize=(2,2),dpi=100)\n","      plt.xlabel('epoch')\n","      plt.ylabel('loss')\n","      plt.plot(losses)\n","      plt.show()\n","          \n","    i=i+1\n","  print('\\n\\n\\t\\t\\tTraining is done')   \n","  print('\\n\\n########### Final Best Results #########################')\n","  print('****** Bests are ******')\n","\n","  return model, best_ser\n","\n","def main():\n","  syst, DAC, fiber, laser, trP = set_attributes()  \n","  \n","\n","  \n","  trP.learningRate = 0.005\n","  trP.layers = (64, )\n","  trP.activation  = nn.SELU()  \n","  trP.leastMovement = 0.0005\n","  trP.itrs = 1500\n","  trP.seq_len = 1\n","  trP.batchSize = 1024 * trP.seq_len # to ensure that stream is devidable into winSize\n","  trP.TSTbatchSize = trP.M * 2048 * trP.seq_len # to ensure that stream is devidable into winSize\n","\n","  SERs = []\n","  for syst.ASE_SNR in range(12,13,1):        \n","    model = None\n","    model, ser = train(syst, DAC, fiber, laser, trP)\n","    SERs.append(ser)\n","  SERs = torch.stack(SERs)\n","  print(SERs)\n","\n","if __name__ == \"__main__\":    \n","  main()"]},{"cell_type":"code","source":[],"metadata":{"id":"F6aJ4wUjzSXa"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"collapsed_sections":["Z6cOYGiq_Dsv"],"authorship_tag":"ABX9TyNY122pTNRa6vjMlLKgXFAT"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}